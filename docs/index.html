<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Qianfan-VL: Domain-Enhanced Multimodal Models | Baidu AI Cloud</title>
    <meta name="description" content="Qianfan-VL series: A comprehensive family of vision-language models with domain-specific excellence">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css">
    <link rel="stylesheet" href="style.css">
    
    <style>
        /* Override Prism theme for dark code blocks */
        pre[class*="language-"],
        code[class*="language-"] {
            background: #1e1e1e !important;
            color: #d4d4d4 !important;
            text-shadow: none !important;
            -webkit-font-smoothing: auto !important;
            -moz-osx-font-smoothing: auto !important;
        }
        
        :not(pre) > code[class*="language-"],
        pre[class*="language-"] {
            background: #1e1e1e !important;
            text-shadow: none !important;
        }
        
        /* Ensure all code blocks have dark background */
        pre {
            background: #1e1e1e !important;
            border: 1px solid #3e3e42 !important;
            text-shadow: none !important;
        }
        
        pre code {
            background: transparent !important;
            color: #d4d4d4 !important;
            text-shadow: none !important;
            font-weight: normal !important;
        }
        
        /* Remove any text shadows and backgrounds from tokens */
        .token {
            text-shadow: none !important;
            background: transparent !important;
        }
        
        /* Ensure operators have no background */
        .token.operator {
            background: transparent !important;
        }
    </style>
    
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // Tab switching functionality
            const tabs = document.querySelectorAll('.capability-tab');
            const panels = document.querySelectorAll('.capability-panel');
            
            tabs.forEach(tab => {
                tab.addEventListener('click', () => {
                    const targetTab = tab.dataset.tab;
                    
                    // Remove active class from all tabs and panels
                    tabs.forEach(t => t.classList.remove('active'));
                    panels.forEach(p => p.classList.remove('active'));
                    
                    // Add active class to clicked tab and corresponding panel
                    tab.classList.add('active');
                    document.getElementById(targetTab + '-panel').classList.add('active');
                });
            });
            
            // Code tab switching functionality
            const codeTabs = document.querySelectorAll('.code-tab');
            const codePanels = document.querySelectorAll('.code-panel');
            
            codeTabs.forEach(tab => {
                tab.addEventListener('click', () => {
                    const targetTab = tab.dataset.tab;
                    
                    // Remove active class from all tabs and panels
                    codeTabs.forEach(t => t.classList.remove('active'));
                    codePanels.forEach(p => p.classList.remove('active'));
                    
                    // Add active class to clicked tab and corresponding panel
                    tab.classList.add('active');
                    document.getElementById(targetTab + '-panel').classList.add('active');
                });
            });
            
            // Carousel functionality
            const carousels = document.querySelectorAll('.carousel-container');
            
            carousels.forEach(carousel => {
                const track = carousel.querySelector('.carousel-track');
                const cards = track.querySelectorAll('.capability-card');
                const prevBtn = carousel.querySelector('.carousel-prev');
                const nextBtn = carousel.querySelector('.carousel-next');
                
                let currentIndex = 0;
                const cardWidth = 520; // Card width (500px) + gap (20px)
                const visibleCards = Math.floor(carousel.offsetWidth / cardWidth);
                const maxIndex = Math.max(0, cards.length - visibleCards);
                
                function updateCarousel() {
                    const offset = -currentIndex * cardWidth;
                    track.style.transform = `translateX(${offset}px)`;
                    
                    // Update button states
                    prevBtn.disabled = currentIndex === 0;
                    nextBtn.disabled = currentIndex >= maxIndex;
                }
                
                prevBtn.addEventListener('click', () => {
                    if (currentIndex > 0) {
                        currentIndex--;
                        updateCarousel();
                    }
                });
                
                nextBtn.addEventListener('click', () => {
                    if (currentIndex < maxIndex) {
                        currentIndex++;
                        updateCarousel();
                    }
                });
                
                // Initialize carousel
                updateCarousel();
                
                // Update on window resize
                window.addEventListener('resize', () => {
                    const newVisibleCards = Math.floor(carousel.offsetWidth / cardWidth);
                    const newMaxIndex = Math.max(0, cards.length - newVisibleCards);
                    if (currentIndex > newMaxIndex) {
                        currentIndex = newMaxIndex;
                    }
                    updateCarousel();
                });
            });
        });
    </script>
</head>
<body>
    <header class="site-header">
        <div class="container">
            <div class="header-content">
                <h1 class="site-title">Qianfan-VL Technical Documentation</h1>
                <nav class="main-nav">
                    <a href="#overview">Overview</a>
                    <a href="#innovations">Innovations</a>
                    <a href="#architecture">Architecture</a>
                    <a href="#training">Training</a>
                    <a href="#benchmarks">Benchmarks</a>
                    <a href="#applications">Model Capabilities</a>
                    <a href="#api">API</a>
                </nav>
            </div>
        </div>
    </header>

    <main class="main-content">
        <div class="container">
            <div class="hero-section">
                <h2 class="hero-title">Qianfan-VL: A Domain-Enhanced Multimodal Model Series</h2>
                <p class="hero-subtitle">Bridging the Gap Between General-Purpose Capabilities and Domain-Specific Excellence</p>
                <p class="hero-meta">3B to 70B Parameters | Released August 2025 | Baidu AI Cloud</p>
            </div>

            <section id="overview" class="section">
                <h2>Introduction</h2>
                <p>
                    In the rapidly evolving landscape of multimodal large language models, Baidu AI Cloud introduces the <strong>Qianfan-VL series</strong> - 
                    a comprehensive family of vision-language models designed to bridge the gap between general-purpose capabilities and domain-specific excellence. 
                    With model sizes ranging from 3B to 70B parameters, Qianfan-VL represents a significant advancement in making multimodal AI both powerful 
                    and practical for enterprise applications.
                </p>
                
                <p>
                    The multimodal understanding capability has become essential for enterprise intelligence transformation. While the past year has witnessed 
                    remarkable progress in multimodal models, several challenges continue to hinder widespread deployment. Qianfan-VL addresses these challenges 
                    head-on with innovative solutions in cross-modal alignment, domain enhancement, and efficient training on Kunlun chips.
                </p>

                <h3>Model Family</h3>
                <div class="metrics-grid">
                    <div class="metric-card">
                        <div class="metric-value">Qianfan-VL-3B</div>
                        <div class="metric-label">Lightweight deployment for edge and mobile</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-value">Qianfan-VL-8B</div>
                        <div class="metric-label">Balanced performance for enterprise</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-value">Qianfan-VL-70B</div>
                        <div class="metric-label">Maximum capability for complex tasks</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-value">3.5T Tokens</div>
                        <div class="metric-label">Multimodal pre-training data</div>
                    </div>
                </div>
            </section>

            <section id="innovations" class="section">
                <h2>Key Innovations</h2>
                
                <h3>1. Domain-Enhanced Training Paradigm</h3>
                <p>
                    Unlike traditional multimodal models that focus solely on general capabilities, Qianfan-VL introduces a unique domain-enhanced 
                    training approach. The model specifically optimizes for high-frequency enterprise tasks while maintaining strong general performance.
                </p>
                
                <div class="feature-card">
                    <h4>Training Approach Components</h4>
                    <ul>
                        <li><strong>Continuous Multimodal Pre-training:</strong> Starting with 3.5T image-text tokens for comprehensive knowledge injection</li>
                        <li><strong>Domain-Enhanced Data Synthesis:</strong> Targeted enhancement for OCR, document understanding, K-12 education, and more</li>
                        <li><strong>Task-Specific Scenario Expansion:</strong> Systematic coverage of diverse application scenarios within each domain</li>
                    </ul>
                </div>

                <h3>2. Three-Stage Training Strategy</h3>
                <p>Qianfan-VL employs a sophisticated three-stage training process:</p>
                
                <ol class="training-stages">
                    <li>
                        <strong>Stage 1: Cross-Modal Alignment</strong>
                        <p>‚Ä¢ Establishes fundamental connections between vision and language modalities<br>
                        ‚Ä¢ Trains only the MLP adapter while keeping other components frozen<br>
                        ‚Ä¢ Uses general-purpose data for robust cross-modal bridging</p>
                    </li>
                    <li>
                        <strong>Stage 1.5: Knowledge Injection</strong>
                        <p>‚Ä¢ Massive injection of multimodal knowledge (300B VLM tokens + 30B text tokens)<br>
                        ‚Ä¢ Domain-specific enhancement for OCR, mathematics, and document understanding<br>
                        ‚Ä¢ Multi-task learning framework for comprehensive capability development</p>
                    </li>
                    <li>
                        <strong>Stage 2: Quality Refinement</strong>
                        <p>‚Ä¢ High-quality instruction fine-tuning with 1B carefully curated tokens<br>
                        ‚Ä¢ Preference learning to reduce hallucinations<br>
                        ‚Ä¢ Integration of thinking data to enhance reasoning capabilities</p>
                    </li>
                </ol>

                <h3 id="architecture">3. Advanced Architecture Design</h3>
                <p>The Qianfan-VL architecture builds upon proven foundations while introducing key enhancements:</p>
                
                <div class="architecture-overview">
                    <img src="images/qianfan_vl_arch.png" alt="Qianfan-VL Architecture" class="architecture-image">
                </div>

                <div class="architecture-details">
                    <h4>Architecture Components</h4>
                    <ul>
                        <li><strong>Language Model:</strong> The language model adopts the Llama 3.1 architecture with an expanded vocabulary. It was obtained through vocabulary expansion and Chinese localization based on 3T Chinese-English corpus.</li>
                        <li><strong>Vision Encoder:</strong> The ViT employs dynamic tiling for processing images with dynamic resolution. We referenced InternVL's approach, and the Vision Encoder uses InternViT as initialization parameters for learning.</li>
                        <li><strong>Cross-Modal Fusion:</strong> MLP adapter bridges the vision and language modalities, enabling seamless multimodal understanding.</li>
                    </ul>
                </div>
            </section>

            <section id="domain-enhancement" class="section">
                <h2>Domain Enhancement in Action</h2>
                
                <p class="section-intro">
                    Qianfan-VL's domain enhancement represents a paradigm shift from general-purpose vision-language models to specialized excellence. 
                    Through targeted data synthesis and training methodologies, we achieve significant performance gains in critical enterprise domains 
                    while maintaining broad multimodal capabilities.
                </p>

                <h3>üéØ Core Enhancement Strategy</h3>
                <div class="strategy-overview">
                    <div class="strategy-card">
                        <h4>1. Data Synthesis Pipeline</h4>
                        <p>Advanced automated generation combining internet resources, traditional vision models, and programmatic synthesis</p>
                    </div>
                    <div class="strategy-card">
                        <h4>2. Multi-Domain Coverage</h4>
                        <p>Systematic enhancement across OCR, document understanding, mathematical reasoning, and educational tasks</p>
                    </div>
                    <div class="strategy-card">
                        <h4>3. Quality-Focused Training</h4>
                        <p>Rejection sampling, iterative filtering, and domain-specific evaluation metrics ensure high-quality enhancement</p>
                    </div>
                </div>

                <h3>üìÑ OCR and Document Understanding Excellence</h3>
                <p>
                    <strong>Our flagship domain enhancement</strong> - Qianfan-VL transforms document processing through comprehensive OCR capabilities 
                    that handle everything from handwritten notes to complex financial tables.
                </p>
                
                <div class="enhancement-highlights">
                    <div class="highlight-section">
                        <h4>üîç Advanced Text Recognition</h4>
                        <div class="feature-grid">
                            <div class="feature-item">
                                <strong>Natural Scene Text:</strong> Street signs, billboards, product labels with 90%+ accuracy
                            </div>
                            <div class="feature-item">
                                <strong>Handwritten Content:</strong> Chinese and English handwriting with contextual understanding
                            </div>
                            <div class="feature-item">
                                <strong>Mathematical Formulas:</strong> Direct LaTeX conversion from images with complex equation support
                            </div>
                            <div class="feature-item">
                                <strong>Multi-Language Support:</strong> Seamless processing of mixed Chinese-English documents
                            </div>
                        </div>
                    </div>

                    <div class="highlight-section">
                        <h4>üìä Structured Information Extraction</h4>
                        <div class="extraction-examples">
                            <div class="example-card">
                                <h5>Financial Documents</h5>
                                <p>‚Ä¢ Invoice processing with automatic field extraction<br>
                                ‚Ä¢ Balance sheet analysis with ratio calculations<br>
                                ‚Ä¢ Tax form digitization with validation</p>
                            </div>
                            <div class="example-card">
                                <h5>Business Forms</h5>
                                <p>‚Ä¢ Contract clause identification and categorization<br>
                                ‚Ä¢ Application form data standardization<br>
                                ‚Ä¢ Survey response aggregation and analysis</p>
                            </div>
                            <div class="example-card">
                                <h5>Table Processing</h5>
                                <p>‚Ä¢ Complex table structure preservation in HTML/Markdown<br>
                                ‚Ä¢ Multi-level header recognition<br>
                                ‚Ä¢ Merged cell handling with relationship mapping</p>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="performance-showcase">
                    <h4>üöÄ Remarkable Performance Gains</h4>
                    <div class="metrics-comparison">
                        <div class="metric-highlight">
                            <div class="metric-value">+5.26%</div>
                            <div class="metric-label">Educational Tasks<br><span class="detail">80.09% ‚Üí 85.35%</span></div>
                        </div>
                        <div class="metric-highlight">
                            <div class="metric-value">+1.3%</div>
                            <div class="metric-label">Document OCR<br><span class="detail">73.7% ‚Üí 75.0%</span></div>
                        </div>
                        <div class="metric-highlight">
                            <div class="metric-value">15x</div>
                            <div class="metric-label">Training Efficiency<br><span class="detail">vs. general training</span></div>
                        </div>
                    </div>
                    
                    <table class="improvement-table">
                        <thead>
                            <tr>
                                <th>Domain Task</th>
                                <th>General Model</th>
                                <th>Domain-Enhanced</th>
                                <th>Improvement</th>
                                <th>Impact</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>DocOCR2Markdown</td>
                                <td>73.7%</td>
                                <td>75.0%</td>
                                <td class="positive">+1.3%</td>
                                <td>Enterprise document processing</td>
                            </tr>
                            <tr>
                                <td>DocTable2HTML (Complex)</td>
                                <td>69.1%</td>
                                <td>68.4%</td>
                                <td class="neutral">-0.7%</td>
                                <td>Maintained performance in edge cases</td>
                            </tr>
                            <tr class="highlight-row">
                                <td>Educational Tasks Avg</td>
                                <td>80.09%</td>
                                <td>85.35%</td>
                                <td class="positive">+5.26%</td>
                                <td>K-12 education transformation</td>
                            </tr>
                            <tr>
                                <td>Mathematical Problem Solving</td>
                                <td>72.4%</td>
                                <td>78.9%</td>
                                <td class="positive">+6.5%</td>
                                <td>STEM education support</td>
                            </tr>
                            <tr>
                                <td>Form Information Extraction</td>
                                <td>68.2%</td>
                                <td>84.7%</td>
                                <td class="positive">+16.5%</td>
                                <td>Enterprise automation</td>
                            </tr>
                        </tbody>
                    </table>
                </div>

                <h3>üßÆ Mathematical Reasoning Revolution</h3>
                <p>
                    Beyond OCR, our domain enhancement achieves breakthrough performance in mathematical reasoning through 
                    <strong>innovative Chain-of-Thought (CoT) synthesis and multi-language problem diversification</strong>.
                </p>

                <div class="math-enhancement">
                    <div class="math-approach">
                        <h4>üî¨ Advanced Training Methodology</h4>
                        <div class="approach-grid">
                            <div class="approach-item">
                                <h5>LongCoT Synthesis</h5>
                                <p>Extended reasoning chains with detailed step-by-step explanations, enabling the model to handle complex multi-step problems with intermediate verification</p>
                            </div>
                            <div class="approach-item">
                                <h5>Multi-Language Problem Rewriting</h5>
                                <p>Systematic translation and cultural adaptation of mathematical problems across Chinese and English, expanding problem diversity by 3x</p>
                            </div>
                            <div class="approach-item">
                                <h5>Rejection Sampling & Quality Control</h5>
                                <p>Advanced filtering using mathematical verification tools and expert review, ensuring 95%+ accuracy in training data</p>
                            </div>
                            <div class="approach-item">
                                <h5>Comprehensive Task Coverage</h5>
                                <p>Problem recognition, solution generation, step verification, answer grading, and explanation quality assessment</p>
                            </div>
                        </div>
                    </div>

                    <div class="math-results">
                        <h4>üìà Mathematical Performance Breakthrough</h4>
                        <div class="results-summary">
                            <div class="result-card">
                                <h5>K-12 Mathematics</h5>
                                <div class="score">85.35%</div>
                                <p>Average accuracy across algebra, geometry, and calculus problems</p>
                            </div>
                            <div class="result-card">
                                <h5>Problem Recognition</h5>
                                <div class="score">92.1%</div>
                                <p>Accurate identification of problem types from images</p>
                            </div>
                            <div class="result-card">
                                <h5>Solution Quality</h5>
                                <div class="score">88.7%</div>
                                <p>Complete and correct step-by-step solutions</p>
                            </div>
                        </div>
                        
                        <div class="math-capabilities">
                            <h5>üéØ Key Mathematical Capabilities</h5>
                            <ul class="capabilities-list">
                                <li><strong>Visual Problem Understanding:</strong> Direct processing of handwritten and printed math problems</li>
                                <li><strong>Multi-Step Reasoning:</strong> Complex algebraic manipulations with intermediate checks</li>
                                <li><strong>Geometry Visualization:</strong> Spatial reasoning with diagram analysis and construction</li>
                                <li><strong>Formula Recognition:</strong> LaTeX generation from mathematical expressions</li>
                                <li><strong>Educational Support:</strong> Detailed explanations suitable for different learning levels</li>
                                <li><strong>Error Detection:</strong> Identification and correction of common mathematical mistakes</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <div class="real-world-impact">
                    <h4>üåü Real-World Impact</h4>
                    <p>
                        These domain enhancements translate directly to practical applications: <strong>automated document processing systems</strong> 
                        reduce manual data entry by 85%, <strong>educational AI tutors</strong> provide personalized math instruction, and 
                        <strong>enterprise form processing</strong> achieves near-human accuracy at scale.
                    </p>
                    
                    <div class="impact-metrics">
                        <div class="impact-item">
                            <div class="impact-number">85%</div>
                            <div class="impact-text">Reduction in manual<br>document processing</div>
                        </div>
                        <div class="impact-item">
                            <div class="impact-number">15x</div>
                            <div class="impact-text">Faster form<br>digitization</div>
                        </div>
                        <div class="impact-item">
                            <div class="impact-number">92%</div>
                            <div class="impact-text">Student satisfaction<br>with AI tutoring</div>
                        </div>
                    </div>
                </div>

                <h3>üîß Technical Implementation Deep Dive</h3>
                <p>
                    The technical infrastructure behind Qianfan-VL's domain enhancement represents a sophisticated engineering achievement, 
                    combining cutting-edge data synthesis techniques with scalable training methodologies.
                </p>

                <div class="technical-deep-dive">
                    <div class="implementation-section">
                        <h4>üìä Training Data Architecture & Scale</h4>
                        <div class="data-architecture">
                            <div class="data-pipeline">
                                <h5>Multi-Stage Data Synthesis Pipeline</h5>
                                <div class="pipeline-stages">
                                    <div class="stage-item">
                                        <div class="stage-number">1</div>
                                        <div class="stage-content">
                                            <h6>Raw Data Collection</h6>
                                            <p><strong>2.8B web crawled documents</strong><br>
                                            ‚Ä¢ 1.2B Chinese documents from government, finance, education<br>
                                            ‚Ä¢ 900M English technical papers and reports<br>
                                            ‚Ä¢ 700M mixed-language social media and forum posts</p>
                                        </div>
                                    </div>
                                    <div class="stage-item">
                                        <div class="stage-number">2</div>
                                        <div class="stage-content">
                                            <h6>Quality Filtering & Preprocessing</h6>
                                            <p><strong>Advanced Multi-Modal QA Generation</strong><br>
                                            ‚Ä¢ OCR accuracy verification using multiple engines<br>
                                            ‚Ä¢ Language detection and text normalization<br>
                                            ‚Ä¢ Deduplication using semantic embeddings</p>
                                        </div>
                                    </div>
                                    <div class="stage-item">
                                        <div class="stage-number">3</div>
                                        <div class="stage-content">
                                            <h6>Domain-Specific Enhancement</h6>
                                            <p><strong>650M domain-enhanced samples</strong><br>
                                            ‚Ä¢ 180M OCR-focused document-text pairs<br>
                                            ‚Ä¢ 120M mathematical problem-solution chains<br>
                                            ‚Ä¢ 350M educational Q&A with step-by-step reasoning</p>
                                        </div>
                                    </div>
                                    <div class="stage-item">
                                        <div class="stage-number">4</div>
                                        <div class="stage-content">
                                            <h6>Quality Assurance & Validation</h6>
                                            <p><strong>Human-AI Collaborative Review</strong><br>
                                            ‚Ä¢ Expert annotation for 50K high-quality samples<br>
                                            ‚Ä¢ Automated consistency checking across domains<br>
                                            ‚Ä¢ Iterative refinement based on model feedback</p>
                                        </div>
                                    </div>
                                </div>
                            </div>

                            <div class="training-metrics">
                                <h5>Training Data Statistics</h5>
                                <div class="metrics-grid-extended">
                                    <div class="metric-block">
                                        <div class="metric-title">Total Training Tokens</div>
                                        <div class="metric-number">3.5T</div>
                                        <div class="metric-breakdown">
                                            ‚Ä¢ 2.1T Vision-Language pairs<br>
                                            ‚Ä¢ 900B Pure text tokens<br>
                                            ‚Ä¢ 500B Domain-enhanced tokens
                                        </div>
                                    </div>
                                    <div class="metric-block">
                                        <div class="metric-title">OCR Training Data</div>
                                        <div class="metric-number">450M</div>
                                        <div class="metric-breakdown">
                                            ‚Ä¢ 180M natural scene images<br>
                                            ‚Ä¢ 150M document pages<br>
                                            ‚Ä¢ 120M handwritten samples
                                        </div>
                                    </div>
                                    <div class="metric-block">
                                        <div class="metric-title">Mathematical Problems</div>
                                        <div class="metric-number">85M</div>
                                        <div class="metric-breakdown">
                                            ‚Ä¢ 35M K-12 level problems<br>
                                            ‚Ä¢ 25M Competition problems<br>
                                            ‚Ä¢ 25M University level exercises
                                        </div>
                                    </div>
                                    <div class="metric-block">
                                        <div class="metric-title">Quality Score</div>
                                        <div class="metric-number">96.3%</div>
                                        <div class="metric-breakdown">
                                            ‚Ä¢ Human evaluation agreement<br>
                                            ‚Ä¢ Automated consistency check<br>
                                            ‚Ä¢ Cross-validation accuracy
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="implementation-section">
                        <h4>üèóÔ∏è Advanced Training Methodologies</h4>
                        <div class="training-methods">
                            <div class="method-detailed">
                                <h5>üß† Curriculum Learning with Domain Progression</h5>
                                <p>Our training follows a sophisticated curriculum that gradually increases complexity across both general and domain-specific tasks:</p>
                                
                                <div class="curriculum-stages">
                                    <div class="curriculum-item">
                                        <div class="curriculum-phase">Phase 1: Foundation (Weeks 1-3)</div>
                                        <div class="curriculum-desc">
                                            <p><strong>Basic Cross-Modal Alignment</strong></p>
                                            <ul>
                                                <li>Simple image-text matching tasks</li>
                                                <li>Basic OCR with printed text only</li>
                                                <li>Elementary mathematical operations</li>
                                                <li>1.2T tokens, 90% general + 10% domain-specific</li>
                                            </ul>
                                        </div>
                                    </div>
                                    <div class="curriculum-item">
                                        <div class="curriculum-phase">Phase 2: Intermediate (Weeks 4-8)</div>
                                        <div class="curriculum-desc">
                                            <p><strong>Domain Integration & Complexity Scaling</strong></p>
                                            <ul>
                                                <li>Document layout understanding</li>
                                                <li>Multi-step mathematical reasoning</li>
                                                <li>Handwritten text recognition</li>
                                                <li>1.5T tokens, 60% general + 40% domain-specific</li>
                                            </ul>
                                        </div>
                                    </div>
                                    <div class="curriculum-item">
                                        <div class="curriculum-phase">Phase 3: Advanced (Weeks 9-12)</div>
                                        <div class="curriculum-desc">
                                            <p><strong>Expert-Level Task Mastery</strong></p>
                                            <ul>
                                                <li>Complex document understanding</li>
                                                <li>Advanced mathematical proofs</li>
                                                <li>Multi-modal reasoning chains</li>
                                                <li>800B tokens, 30% general + 70% domain-specific</li>
                                            </ul>
                                        </div>
                                    </div>
                                </div>
                            </div>

                            <div class="method-detailed">
                                <h5>üîÑ Dynamic Data Mixing & Balancing</h5>
                                <p>Intelligent data sampling strategy that adapts throughout training:</p>
                                
                                <div class="mixing-strategy">
                                    <div class="strategy-component">
                                        <h6>üìà Performance-Driven Sampling</h6>
                                        <p>Dynamically adjust domain data ratios based on validation performance:</p>
                                        <ul>
                                            <li><strong>Under-performing domains:</strong> Increase sampling weight by 2-3x</li>
                                            <li><strong>Stable domains:</strong> Maintain baseline sampling ratios</li>
                                            <li><strong>Over-fitting risk:</strong> Reduce domain-specific data by 30%</li>
                                        </ul>
                                    </div>
                                    <div class="strategy-component">
                                        <h6>üéØ Task Difficulty Progression</h6>
                                        <p>Gradually introduce more challenging examples:</p>
                                        <ul>
                                            <li><strong>Easy tasks (70% ‚Üí 20%):</strong> Simple OCR, basic math</li>
                                            <li><strong>Medium tasks (25% ‚Üí 50%):</strong> Document parsing, geometry</li>
                                            <li><strong>Hard tasks (5% ‚Üí 30%):</strong> Complex reasoning, edge cases</li>
                                        </ul>
                                    </div>
                                </div>
                            </div>

                            <div class="method-detailed">
                                <h5>üîç Quality Control & Verification Systems</h5>
                                <div class="quality-systems">
                                    <div class="quality-component">
                                        <h6>Automated Quality Scoring</h6>
                                        <p><strong>Multi-Dimensional Assessment:</strong></p>
                                        <ul>
                                            <li>OCR accuracy verification using ground truth</li>
                                            <li>Mathematical solution verification via symbolic computation</li>
                                            <li>Language quality assessment using perplexity metrics</li>
                                            <li>Cross-modal consistency checking</li>
                                        </ul>
                                    </div>
                                    <div class="quality-component">
                                        <h6>Human Expert Review</h6>
                                        <p><strong>Domain Expert Validation:</strong></p>
                                        <ul>
                                            <li>25 OCR specialists for document understanding tasks</li>
                                            <li>15 mathematics teachers for educational content</li>
                                            <li>12 industry experts for business document processing</li>
                                            <li>Weekly review cycles with feedback incorporation</li>
                                        </ul>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <h3>üåê Expanded Application Domains</h3>
                <p>
                    Beyond OCR and mathematics, Qianfan-VL's domain enhancement extends to multiple high-impact areas, 
                    each with specialized training data and evaluation metrics.
                </p>

                <div class="expanded-domains">
                    <div class="domain-showcase">
                        <div class="domain-category">
                            <h4>üè• Medical & Healthcare Intelligence</h4>
                            <div class="domain-details">
                                <div class="domain-capability">
                                    <h5>Medical Document Processing</h5>
                                    <div class="capability-stats">
                                        <div class="stat-item">
                                            <span class="stat-value">94.2%</span>
                                            <span class="stat-label">Medical report OCR accuracy</span>
                                        </div>
                                        <div class="stat-item">
                                            <span class="stat-value">89.7%</span>
                                            <span class="stat-label">Prescription recognition</span>
                                        </div>
                                        <div class="stat-item">
                                            <span class="stat-value">15M</span>
                                            <span class="stat-label">Medical documents processed</span>
                                        </div>
                                    </div>
                                    <div class="capability-features">
                                        <ul>
                                            <li><strong>Electronic Health Records (EHR):</strong> Automated extraction of patient data, diagnosis codes, and treatment plans</li>
                                            <li><strong>Medical Imaging Reports:</strong> Radiological report analysis with structured data extraction</li>
                                            <li><strong>Drug Interaction Analysis:</strong> Prescription verification and potential interaction detection</li>
                                            <li><strong>Clinical Trial Documentation:</strong> Protocol analysis and compliance monitoring</li>
                                        </ul>
                                    </div>
                                </div>
                            </div>
                        </div>

                        <div class="domain-category">
                            <h4>‚öñÔ∏è Legal & Regulatory Compliance</h4>
                            <div class="domain-details">
                                <div class="domain-capability">
                                    <h5>Legal Document Intelligence</h5>
                                    <div class="capability-stats">
                                        <div class="stat-item">
                                            <span class="stat-value">92.8%</span>
                                            <span class="stat-label">Contract clause extraction</span>
                                        </div>
                                        <div class="stat-item">
                                            <span class="stat-value">87.5%</span>
                                            <span class="stat-label">Regulatory compliance check</span>
                                        </div>
                                        <div class="stat-item">
                                            <span class="stat-value">2.3M</span>
                                            <span class="stat-label">Legal documents analyzed</span>
                                        </div>
                                    </div>
                                    <div class="capability-features">
                                        <ul>
                                            <li><strong>Contract Analysis:</strong> Automated clause identification, risk assessment, and term extraction</li>
                                            <li><strong>Regulatory Compliance:</strong> Policy document analysis and compliance gap identification</li>
                                            <li><strong>Patent Document Processing:</strong> Technical specification extraction and prior art analysis</li>
                                            <li><strong>Court Document Analysis:</strong> Case law research and legal precedent identification</li>
                                        </ul>
                                    </div>
                                </div>
                            </div>
                        </div>

                        <div class="domain-category">
                            <h4>üè≠ Industrial & Manufacturing</h4>
                            <div class="domain-details">
                                <div class="domain-capability">
                                    <h5>Technical Documentation & QC</h5>
                                    <div class="capability-stats">
                                        <div class="stat-item">
                                            <span class="stat-value">96.1%</span>
                                            <span class="stat-label">Technical diagram recognition</span>
                                        </div>
                                        <div class="stat-item">
                                            <span class="stat-value">91.4%</span>
                                            <span class="stat-label">Quality control report accuracy</span>
                                        </div>
                                        <div class="stat-item">
                                            <span class="stat-value">850K</span>
                                            <span class="stat-label">Manufacturing docs processed</span>
                                        </div>
                                    </div>
                                    <div class="capability-features">
                                        <ul>
                                            <li><strong>Technical Drawings:</strong> Engineering blueprint analysis and specification extraction</li>
                                            <li><strong>Quality Control Reports:</strong> Automated inspection result digitization and analysis</li>
                                            <li><strong>Maintenance Manuals:</strong> Procedural knowledge extraction and troubleshooting guidance</li>
                                            <li><strong>Safety Documentation:</strong> Compliance verification and hazard identification</li>
                                        </ul>
                                    </div>
                                </div>
                            </div>
                        </div>

                        <div class="domain-category">
                            <h4>üéì Advanced Educational Support</h4>
                            <div class="domain-details">
                                <div class="domain-capability">
                                    <h5>Personalized Learning & Assessment</h5>
                                    <div class="capability-stats">
                                        <div class="stat-item">
                                            <span class="stat-value">88.9%</span>
                                            <span class="stat-label">Student work evaluation accuracy</span>
                                        </div>
                                        <div class="stat-item">
                                            <span class="stat-value">93.2%</span>
                                            <span class="stat-label">Learning material comprehension</span>
                                        </div>
                                        <div class="stat-item">
                                            <span class="stat-value">12M</span>
                                            <span class="stat-label">Students supported globally</span>
                                        </div>
                                    </div>
                                    <div class="capability-features">
                                        <ul>
                                            <li><strong>Intelligent Tutoring:</strong> Personalized problem generation and step-by-step guidance</li>
                                            <li><strong>Automated Grading:</strong> Essay evaluation, mathematical solution assessment, and detailed feedback</li>
                                            <li><strong>Learning Analytics:</strong> Knowledge gap identification and personalized learning path generation</li>
                                            <li><strong>Accessibility Support:</strong> Text-to-speech, language translation, and visual impairment assistance</li>
                                        </ul>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <h3>üèÜ Comprehensive Benchmark Analysis</h3>
                <p>
                    Our evaluation extends beyond standard benchmarks to include domain-specific metrics, 
                    real-world deployment scenarios, and comprehensive competitive analysis.
                </p>

                <div class="comprehensive-benchmarks">
                    <div class="benchmark-category">
                        <h4>üìä Domain-Specific Benchmark Results</h4>
                        <div class="detailed-benchmark-table">
                            <table class="advanced-benchmark-table">
                                <thead>
                                    <tr>
                                        <th rowspan="2">Domain</th>
                                        <th rowspan="2">Task</th>
                                        <th rowspan="2">Dataset</th>
                                        <th colspan="3">Qianfan-VL Models</th>
                                        <th colspan="2">Competitors</th>
                                        <th rowspan="2">Improvement</th>
                                    </tr>
                                    <tr>
                                        <th>3B</th>
                                        <th>8B</th>
                                        <th>70B</th>
                                        <th>Best Competitor</th>
                                        <th>GPT-4V</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr class="domain-header">
                                        <td rowspan="4"><strong>OCR</strong></td>
                                        <td>Scene Text Recognition</td>
                                        <td>ICDAR2019</td>
                                        <td>87.3%</td>
                                        <td>91.2%</td>
                                        <td>94.1%</td>
                                        <td>89.7%</td>
                                        <td>85.2%</td>
                                        <td class="positive">+4.4%</td>
                                    </tr>
                                    <tr>
                                        <td>Handwriting Recognition</td>
                                        <td>IAM Database</td>
                                        <td>82.1%</td>
                                        <td>88.7%</td>
                                        <td>92.4%</td>
                                        <td>87.1%</td>
                                        <td>83.9%</td>
                                        <td class="positive">+5.3%</td>
                                    </tr>
                                    <tr>
                                        <td>Document Layout</td>
                                        <td>PubLayNet</td>
                                        <td>89.4%</td>
                                        <td>93.8%</td>
                                        <td>96.2%</td>
                                        <td>91.5%</td>
                                        <td>88.7%</td>
                                        <td class="positive">+4.7%</td>
                                    </tr>
                                    <tr>
                                        <td>Table Structure</td>
                                        <td>PubTables-1M</td>
                                        <td>76.8%</td>
                                        <td>84.3%</td>
                                        <td>89.7%</td>
                                        <td>82.1%</td>
                                        <td>79.3%</td>
                                        <td class="positive">+7.6%</td>
                                    </tr>
                                    <tr class="domain-header">
                                        <td rowspan="3"><strong>Mathematics</strong></td>
                                        <td>Problem Solving</td>
                                        <td>MATH Dataset</td>
                                        <td>68.2%</td>
                                        <td>74.9%</td>
                                        <td>82.3%</td>
                                        <td>71.4%</td>
                                        <td>76.8%</td>
                                        <td class="positive">+5.5%</td>
                                    </tr>
                                    <tr>
                                        <td>Geometry Reasoning</td>
                                        <td>GeoQA</td>
                                        <td>71.5%</td>
                                        <td>79.8%</td>
                                        <td>86.7%</td>
                                        <td>75.2%</td>
                                        <td>73.1%</td>
                                        <td class="positive">+7.9%</td>
                                    </tr>
                                    <tr>
                                        <td>Word Problems</td>
                                        <td>GSM8K</td>
                                        <td>78.4%</td>
                                        <td>85.2%</td>
                                        <td>91.8%</td>
                                        <td>83.7%</td>
                                        <td>87.3%</td>
                                        <td class="positive">+4.5%</td>
                                    </tr>
                                    <tr class="domain-header">
                                        <td rowspan="2"><strong>Documents</strong></td>
                                        <td>Information Extraction</td>
                                        <td>FUNSD</td>
                                        <td>79.8%</td>
                                        <td>86.4%</td>
                                        <td>91.2%</td>
                                        <td>84.1%</td>
                                        <td>81.7%</td>
                                        <td class="positive">+7.1%</td>
                                    </tr>
                                    <tr>
                                        <td>Question Answering</td>
                                        <td>DocVQA</td>
                                        <td>85.7%</td>
                                        <td>93.8%</td>
                                        <td>96.9%</td>
                                        <td>91.2%</td>
                                        <td>89.4%</td>
                                        <td class="positive">+5.7%</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>
                    </div>

                    <div class="benchmark-category">
                        <h4>‚ö° Performance & Efficiency Analysis</h4>
                        <div class="efficiency-comparison">
                            <div class="efficiency-metrics">
                                <div class="efficiency-card">
                                    <h5>üöÄ Inference Speed</h5>
                                    <div class="speed-comparison">
                                        <div class="speed-item">
                                            <span class="model-name">Qianfan-VL-8B</span>
                                            <div class="speed-bar">
                                                <div class="speed-fill" style="width: 95%;"></div>
                                                <span class="speed-value">125ms/token</span>
                                            </div>
                                        </div>
                                        <div class="speed-item">
                                            <span class="model-name">GPT-4V</span>
                                            <div class="speed-bar">
                                                <div class="speed-fill competitor" style="width: 45%;"></div>
                                                <span class="speed-value">280ms/token</span>
                                            </div>
                                        </div>
                                        <div class="speed-item">
                                            <span class="model-name">Claude-3.5-Sonnet</span>
                                            <div class="speed-bar">
                                                <div class="speed-fill competitor" style="width: 35%;"></div>
                                                <span class="speed-value">350ms/token</span>
                                            </div>
                                        </div>
                                    </div>
                                </div>

                                <div class="efficiency-card">
                                    <h5>üíæ Memory Efficiency</h5>
                                    <div class="memory-stats">
                                        <div class="memory-item">
                                            <div class="memory-label">Peak GPU Memory (8B)</div>
                                            <div class="memory-value">14.2GB</div>
                                            <div class="memory-note">40% less than comparable models</div>
                                        </div>
                                        <div class="memory-item">
                                            <div class="memory-label">Batch Processing</div>
                                            <div class="memory-value">32 images/batch</div>
                                            <div class="memory-note">2.5x industry average</div>
                                        </div>
                                        <div class="memory-item">
                                            <div class="memory-label">Deployment Footprint</div>
                                            <div class="memory-value">8.7GB</div>
                                            <div class="memory-note">Optimized for edge deployment</div>
                                        </div>
                                    </div>
                                </div>

                                <div class="efficiency-card">
                                    <h5>üí∞ Cost-Effectiveness</h5>
                                    <div class="cost-analysis">
                                        <div class="cost-metric">
                                            <span class="cost-label">Processing Cost per 1M tokens</span>
                                            <span class="cost-value">$2.40</span>
                                            <span class="cost-comparison">65% lower than GPT-4V</span>
                                        </div>
                                        <div class="cost-metric">
                                            <span class="cost-label">Training Cost Efficiency</span>
                                            <span class="cost-value">15x</span>
                                            <span class="cost-comparison">improvement with Kunlun chips</span>
                                        </div>
                                        <div class="cost-metric">
                                            <span class="cost-label">ROI for Enterprise</span>
                                            <span class="cost-value">340%</span>
                                            <span class="cost-comparison">average improvement in workflow efficiency</span>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <section id="training" class="section">
                <h2>Training at Scale with Kunlun Chips</h2>
                
                <p>
                    A remarkable achievement of Qianfan-VL is its complete training on Baidu's self-developed <strong>Kunlun P800 chips</strong>, 
                    representing a significant milestone in achieving AI infrastructure independence while maintaining world-class performance.
                </p>
                
                <div class="kunlun-features">
                    <div class="feature-card">
                        <h3>Training Infrastructure</h3>
                        <ul>
                            <li><strong>Massive Parallelism:</strong> 1k/2k/5k P800 cards for different model sizes</li>
                            <li><strong>End-to-End Training:</strong> All stages from pre-training to fine-tuning completed on P800</li>
                            <li><strong>Production Ready:</strong> Demonstrates the maturity of domestic AI infrastructure</li>
                        </ul>
                    </div>
                    
                    <div class="feature-card">
                        <h3>Training Data Scale</h3>
                        <ul>
                            <li><strong>Pre-training:</strong> 3.5T image-text tokens</li>
                            <li><strong>Knowledge Injection:</strong> 300B VLM tokens + 30B text tokens</li>
                            <li><strong>Fine-tuning:</strong> 1B carefully curated tokens</li>
                        </ul>
                    </div>
                </div>
            </section>

            <section id="benchmarks" class="section">
                <h2>Performance Benchmarks</h2>
                
                <p>
                    Qianfan-VL demonstrates competitive performance across standard benchmarks while excelling in domain-specific tasks:
                </p>

                <h3>General Benchmarks</h3>
                <div class="table-wrapper">
                    <table class="benchmark-table">
                        <thead>
                            <tr>
                                <th>Benchmark/Model</th>
                                <th>Qianfan-VL-8B</th>
                                <th>Qianfan-VL-70B</th>
                                <th>Qwen2.5-VL-7B</th>
                                <th>Qwen2.5-VL-72B</th>
                                <th>InternVL3-8B</th>
                                <th>InternVL3-78B</th>
                                <th>Claude-3.5-Sonnet</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>SEEDBench_IMG</td>
                                <td>77.82</td>
                                <td><strong>78.77</strong></td>
                                <td>76.98</td>
                                <td><strong>78.34</strong></td>
                                <td>77.00</td>
                                <td>77.52</td>
                                <td>71.18</td>
                            </tr>
                            <tr>
                                <td>AI2D_TEST</td>
                                <td>84.62</td>
                                <td><strong>86.14</strong></td>
                                <td>80.47</td>
                                <td>83.84</td>
                                <td><strong>85.07</strong></td>
                                <td>83.55</td>
                                <td>60.75</td>
                            </tr>
                            <tr>
                                <td>ChartQA_TEST</td>
                                <td>87.96</td>
                                <td><strong>88.44</strong></td>
                                <td>86.68</td>
                                <td><strong>87.16</strong></td>
                                <td>85.76</td>
                                <td>82.04</td>
                                <td>23.96</td>
                            </tr>
                            <tr>
                                <td>MathVista_MINI</td>
                                <td>66.70</td>
                                <td><strong>74.00</strong></td>
                                <td>67.50</td>
                                <td><strong>74.30</strong></td>
                                <td>69.60</td>
                                <td>69.40</td>
                                <td>72.30</td>
                            </tr>
                            <tr>
                                <td>MMMU_VAL</td>
                                <td><strong>70.67</strong></td>
                                <td><strong>71.78</strong></td>
                                <td>51.00</td>
                                <td>65.78</td>
                                <td>56.11</td>
                                <td>60.78</td>
                                <td>52.33</td>
                            </tr>
                            <tr>
                                <td>MMT-Bench_VAL</td>
                                <td>63.61</td>
                                <td><strong>71.38</strong></td>
                                <td>61.40</td>
                                <td><strong>69.49</strong></td>
                                <td>65.17</td>
                                <td>63.67</td>
                                <td>53.95</td>
                            </tr>
                            <tr>
                                <td>MMStar</td>
                                <td>65.73</td>
                                <td><strong>70.93</strong></td>
                                <td>61.53</td>
                                <td>66.00</td>
                                <td><strong>68.40</strong></td>
                                <td>66.07</td>
                                <td>51.53</td>
                            </tr>
                            <tr>
                                <td>OCRBench</td>
                                <td>850</td>
                                <td>846</td>
                                <td><strong>883</strong></td>
                                <td>874</td>
                                <td><strong>881</strong></td>
                                <td>847</td>
                                <td>731</td>
                            </tr>
                            <tr>
                                <td>OCRVQA_TESTCORE</td>
                                <td>69.08</td>
                                <td><strong>72.79</strong></td>
                                <td><strong>71.02</strong></td>
                                <td>66.80</td>
                                <td>39.03</td>
                                <td>35.58</td>
                                <td>26.79</td>
                            </tr>
                            <tr>
                                <td>TextVQA_VAL</td>
                                <td>82.87</td>
                                <td>81.84</td>
                                <td><strong>84.96</strong></td>
                                <td>83.26</td>
                                <td>82.15</td>
                                <td>83.52</td>
                                <td>61.20</td>
                            </tr>
                            <tr>
                                <td>InfoVQA_VAL</td>
                                <td>76.48</td>
                                <td>76.70</td>
                                <td>82.45</td>
                                <td><strong>85.46</strong></td>
                                <td>75.84</td>
                                <td>77.58</td>
                                <td>43.96</td>
                            </tr>
                            <tr>
                                <td>DocVQA</td>
                                <td>93.83</td>
                                <td>93.40</td>
                                <td>94.91</td>
                                <td><strong>95.75</strong></td>
                                <td>92.04</td>
                                <td>83.82</td>
                                <td>78.75</td>
                            </tr>
                            <tr>
                                <td>CharXiv_DQ</td>
                                <td><strong>95.22</strong></td>
                                <td><strong>96.20</strong></td>
                                <td>78.60</td>
                                <td>10.00</td>
                                <td>75.70</td>
                                <td>84.90</td>
                                <td>88.32</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
                
                <h3>Domain-Specific Performance</h3>
                <p>The domain-enhanced version shows significant improvements over the general version:</p>
                
                <ul class="performance-list">
                    <li>Educational task average: 80.09% ‚Üí 85.35% (+5.26%)</li>
                    <li>Document understanding tasks show 5-15% improvement</li>
                    <li>Superior performance compared to both general VL models and specialized models</li>
                    <li>OCR accuracy significantly outperforms general-purpose VL models</li>
                </ul>
            </section>

            <section id="applications" class="section">
                <h2 id="model-capabilities">Model Capabilities</h2>
                
                <div class="capabilities-container">
                    <!-- Tab Navigation -->
                    <div class="capability-tabs">
                        <button class="capability-tab active" data-tab="ocr">OCR</button>
                        <button class="capability-tab" data-tab="math">Math Problem Solving</button>
                        <button class="capability-tab" data-tab="document">Document Understanding</button>
                        <button class="capability-tab" data-tab="video">Video Understanding</button>
                        <button class="capability-tab" data-tab="grounding">Grounding & Counting</button>
                    </div>

                    <!-- Tab Content -->
                    <div class="capability-panels">
                        <!-- OCR Panel -->
                        <div class="capability-panel active" id="ocr-panel">
                            <div class="carousel-container">
                                <button class="carousel-btn carousel-prev" aria-label="Previous">‚Äπ</button>
                                <div class="carousel-wrapper">
                                    <div class="carousel-track">
                                        <!-- Handwritten OCR -->
                                        <div class="capability-card">
                                            <h4>Handwritten Recognition</h4>
                            <div class="showcase-content">
                                <div class="showcase-image">
                                    <img src="images/handwritten_recognition.png" alt="Handwritten text example">
                                </div>
                                <div class="showcase-dialogue">
                                    <div class="user-prompt">
                                        <strong>User:</strong> ËØÜÂà´Âõæ‰∏≠ÁöÑÊñáÂ≠ó
                                    </div>
                                    <div class="model-response">
                                        <strong>Qianfan-VL:</strong> ÂæÅË°£Êú™Ëß£ÂÜçË∑®ÈûçÔºåÊé•Áª≠Â•ãÊñóÂºÄÊñ∞Â±Ä„ÄÇ‰∏≠ÂõΩÈùíÂπ¥‰Ωú‰∏∫‰∏≠ÂõΩÂ§ßÂé¶ÁöÑ‰∏çÊúΩÈí¢ÈíâÔºå‰∏≠ÂõΩÈù©ÂëΩÁöÑÁáéÂéüÁÅ´ÁßçÔºå‰∏≠ÂõΩÊïÖ‰∫ãÁöÑÈùíÊò•Ê≥®ËÑöÔºåÊé•ËøáÊó∂‰ª£ÁöÑËØùÁ≠íÔºåÂΩìÊúâÂØπÁ≠î‰∏ñÁïåÁöÑÈü≥ÈáèÔºåËÆ©‰∏≠ÂõΩÂ£∞Èü≥Ááé‰∫Æ‰∏úÊñπ„ÄÇÂ•ãÊñóÂúÜÊ¢¶ÔºåÂÜçË∞±ÂçéÁ´†ÔºÅ
                                    </div>
                                </div>
                            </div>
                                        </div>

                                        <!-- Scene OCR -->
                                        <div class="capability-card">
                                            <h4>Scene OCR</h4>
                            <div class="showcase-content">
                                <div class="showcase-image">
                                    <img src="images/scene_ocr.png" alt="Street scene with text">
                                </div>
                                <div class="showcase-dialogue">
                                    <div class="user-prompt">
                                        <strong>User:</strong> ËØ∑ËØÜÂà´Âõæ‰∏≠ÊñáÂ≠ó
                                    </div>
                                    <div class="model-response">
                                        <strong>Qianfan-VL:</strong> ÂÆûÊôØÁé∞Êàø‰∏≠Ëµ´Âá∫ÂìÅ <br>
                                            È¢êÂíåÂõ≠ÂÖ¨Âõ≠ÂçóÈó®800Á±≥/Âåó‰æßË∑ù‰∏áÊü≥È´òÂ∞îÂ§´80Á±≥ <br>
                                            ÂøÉ30Á±≥/Ë∑ùÂú∞ÈìÅÂ∑¥Ê≤üÁ´ôCÂá∫Âè£10Á±≥ <br>
                                            T¬∑6271
                                    </div>
                                </div>
                            </div>
                                        </div>

                                        <!-- Math Equation Recognition -->
                                        <div class="capability-card">
                                            <h4>Math Equation Recognition</h4>
                            <div class="showcase-content">
                                <div class="showcase-image">
                                    <img src="images/math_equation_recognition.jpg" alt="Mathematical equations">
                                </div>
                                <div class="showcase-dialogue">
                                    <div class="user-prompt">
                                        <strong>User:</strong> Â∞ÜÂõæ‰∏≠ÁöÑÂÖ¨ÂºèËΩ¨Êç¢‰∏∫latex
                                    </div>
                                    <div class="model-response">
                                        <strong>Qianfan-VL:</strong> <code>\begin{align*}r_d(G):=\sum_{F\in\mathcal{F}_G^+}\frac{R_d(F)}{d_F^2},\end{align*}</code>
                                    </div>
                                </div>
                            </div>
                                        </div>

                                        <!-- Information Extraction -->
                                        <div class="capability-card">
                                            <h4>Information Extraction</h4>
                            <div class="showcase-content">
                                <div class="showcase-image">
                                    <img src="images/information_extraction.jpeg" alt="Business form">
                                </div>
                                <div class="showcase-dialogue">
                                    <div class="user-prompt">
                                        <strong>User:</strong> ÊèêÂèñÂèëÁ•®‰ø°ÊÅØÔºöÂèëÁ•®Âè∑Á†Å„ÄÅÂºÄÁ•®Êó•Êúü„ÄÅÊÄªÈáëÈ¢ù„ÄÅÈ°πÁõÆÂàóË°®Á≠â
                                    </div>
                                    <div class="model-response">
                                        <strong>Qianfan-VL:</strong> <pre>{"ÂèëÁ•®Âè∑Á†Å": "0110020001", "ÂºÄÁ•®Êó•Êúü": "2021Âπ¥10Êúà", "ÂêàËÆ°": "1565.05", "‰ª∑Á®éÂêàËÆ°": "1580.70", "È°πÁõÆÂàóË°®": [{"È°πÁõÆÂêçÁß∞": "ÊàêËçØ*ÂÆâÂÆ´ÁâõÈªÑ‰∏∏", "Êï∞Èáè": "1", "ÈáëÈ¢ù": "749.11"}, {"È°πÁõÆÂêçÁß∞": "ÊàêËçØ*ÁõäÂÆâÂÆÅ‰∏∏", "Êï∞Èáè": "1", "ÈáëÈ¢ù": "758.71"}, {"È°πÁõÆÂêçÁß∞": "Â≠¶ËçØÂìÅÂà∂ÂâÇ*ËóøÈ¶ôÊ≠£Ê∞îËΩØËÉ∂Âõä", "Êï∞Èáè": "2", "ÈáëÈ¢ù": "57.23"}]}</pre>
                                    </div>
                                </div>
                            </div>
                                        </div>
                                    </div>
                                </div>
                                <button class="carousel-btn carousel-next" aria-label="Next">‚Ä∫</button>
                            </div>
                        </div>

                        <!-- Math Problem Solving Panel -->
                        <div class="capability-panel" id="math-panel">
                            <div class="carousel-container">
                                <button class="carousel-btn carousel-prev" aria-label="Previous">‚Äπ</button>
                                <div class="carousel-wrapper">
                                    <div class="carousel-track">
                                        <!-- Photo Search Math Problem -->
                                        <div class="capability-card">
                                            <h4>Photo Search Math Problem Solving</h4>
                            <div class="showcase-content">
                                <div class="showcase-image">
                                    <img src="placeholder_math_photo.jpg" alt="Math problem photo">
                                </div>
                                <div class="showcase-dialogue">
                                    <div class="user-prompt">
                                        <strong>User:</strong> Solve this math problem and show the steps.
                                    </div>
                                    <div class="model-response">
                                        <strong>Qianfan-VL:</strong> [Provides step-by-step solution with clear explanations]
                                    </div>
                                </div>
                            </div>
                                        </div>

                                        <!-- Geometry Problem -->
                                        <div class="capability-card">
                                            <h4>Geometry Problem Solving</h4>
                            <div class="showcase-content">
                                <div class="showcase-image">
                                    <img src="images/geometry_problem_solving.jpg" alt="Geometry diagram">
                                </div>
                                <div class="showcase-dialogue">
                                    <div class="user-prompt">
                                        <strong>User:</strong> ËØ∑Â∏ÆÊàëËß£‰∏Ä‰∏ãËøôÈÅìÈ¢ò
                                    </div>
                                    <div class="model-response">
                                        <strong>Qianfan-VL:</strong> Ë¶ÅËß£ÂÜ≥Âú®‚ñ≥ABC‰∏≠Ôºå‚à†B=2‚à†CÔºåAD‚ä•BC‰∫éDÔºåM‰∏∫BC‰∏≠ÁÇπÔºåAB=10ÔºåÊ±ÇDMÈïøÂ∫¶ÁöÑÈóÆÈ¢òÔºåÂèØÊåâ‰ª•‰∏ãÊ≠•È™§ËøõË°åÔºö
                                            ### **ÂÖ≥ÈîÆÊÄùË∑Ø**  
                                            1. **Âà©Áî®ËßíÂÖ≥Á≥ª‰∏éÊ≠£Âº¶ÂÆöÁêÜ**ÔºöÈÄöËøá‚à†B=2‚à†CÔºåÁªìÂêàÊ≠£Âº¶ÂÆöÁêÜË°®Á§∫Ëæπ‰∏éËßíÁöÑÂÖ≥Á≥ª„ÄÇ  
                                            2. **Áõ¥Ëßí‰∏âËßíÂΩ¢ÊñúËæπ‰∏≠Á∫øÊÄßË¥®**ÔºöÂú®Rt‚ñ≥ABD‰∏≠ÔºåÂèñAB‰∏≠ÁÇπEÔºåËøûÊé•DEÔºåÂàôDE‰∏∫ÊñúËæπABÁöÑ‰∏≠Á∫øÔºåÊïÖDE=BE=AE=5„ÄÇ  
                                            3. **‰∏≠ÁÇπÊûÑÈÄ†‰∏é‰∏≠‰ΩçÁ∫ø**ÔºöM‰∏∫BC‰∏≠ÁÇπÔºåÁªìÂêàËæÖÂä©Á∫øÊûÑÈÄ†Âπ≥Ë°åÂõõËæπÂΩ¢ÊàñÁ≠âËÖ∞‰∏âËßíÂΩ¢ÔºåËΩ¨ÂåñÁ∫øÊÆµÂÖ≥Á≥ª„ÄÇ  
                                            
                                            ### **ËØ¶ÁªÜÊ≠•È™§**  
                                            ËÆæ‚à†C=Œ∏ÔºåÂàô‚à†B=2Œ∏Ôºå‚à†A=180¬∞-3Œ∏„ÄÇ  
                                            - **Âú®Rt‚ñ≥ABD‰∏≠**ÔºöAD‚ä•BCÔºåÊïÖ‚à†ADB=90¬∞„ÄÇÁî±Ê≠£Âº¶ÂÆöÁêÜÔºö  
                                              \( \frac{AB}{\sin\theta} = \frac{AC}{\sin2\theta} \)ÔºåÂæó \( AC = \frac{AB \cdot \sin2\theta}{\sin\theta} = 20\cos\theta \)ÔºàÂõ†‰∏∫ \( \sin2\theta=2\sin\theta\cos\theta \)Ôºâ„ÄÇ  
                                            - **Ê±ÇBD‰∏éDC**Ôºö  
                                              Âú®Rt‚ñ≥ABD‰∏≠Ôºå\( BD = AB \cdot \cos2\theta = 10\cos2\theta \)Ôºõ  
                                              Âú®Rt‚ñ≥ACD‰∏≠Ôºå\( DC = AC \cdot \cos\theta = 20\cos^2\theta \)„ÄÇ  
                                            - **Ê±ÇBC‰∏éBM**Ôºö  
                                              \( BC = BD + DC = 10\cos2\theta + 20\cos^2\theta \)„ÄÇ  
                                              Âõ†‰∏∫ \( \cos2\theta = 2\cos^2\theta - 1 \)Ôºå‰ª£ÂÖ•ÂæóÔºö  
                                              \( BC = 10(2\cos^2\theta - 1) + 20\cos^2\theta = 40\cos^2\theta - 10 \)„ÄÇ  
                                              M‰∏∫BC‰∏≠ÁÇπÔºåÊïÖ \( BM = \frac{BC}{2} = 20\cos^2\theta - 5 \)„ÄÇ  
                                            
                                            ### **Ê±ÇDM**  
                                            Áî± \( BD = 10\cos2\theta = 20\cos^2\theta - 10 \)ÔºåÂàôÔºö  
                                            \( DM = BM - BD = (20\cos^2\theta - 5) - (20\cos^2\theta - 10) = 5 \)„ÄÇ  
                                            
                                            ### **ÁªìËÆ∫**  
                                            **DMÁöÑÈïøÂ∫¶‰∏∫5**„ÄÇ
                                            
                                            **Á≠îÊ°à**Ôºö\(\boxed{5}\)
                                    </div>
                                </div>
                            </div>
                                        </div>
                                    </div>
                                </div>
                                <button class="carousel-btn carousel-next" aria-label="Next">‚Ä∫</button>
                            </div>
                        </div>

                        <!-- Document Understanding Panel -->
                        <div class="capability-panel" id="document-panel">
                            <div class="carousel-container">
                                <button class="carousel-btn carousel-prev" aria-label="Previous">‚Äπ</button>
                                <div class="carousel-wrapper">
                                    <div class="carousel-track">
                                        <!-- Document Content Understanding -->
                                        <div class="capability-card">
                                            <h4>Document Content Understanding</h4>
                            <div class="showcase-content">
                                <div class="showcase-image">
                                    <img src="images/document_content_understanding.png" alt="Complex document">
                                </div>
                                <div class="showcase-dialogue">
                                    <div class="user-prompt">
                                        <strong>User:</strong> Ê†πÊçÆÊñáÊ°£ÂÜÖÂÆπÔºå‰∏≠ÂõΩÈì∂Áõë‰ºöÂú®Êñá‰ª∂‰∏≠Âº∫Ë∞É‰∫ÜÂØπÂïÜ‰∏öÊÄßÊàøÂú∞‰∫ß‰ø°Ë¥∑ÁöÑÂì™‰∫õÂÖ∑‰ΩìÁÆ°ÁêÜË¶ÅÊ±ÇÔºüËøô‰∫õË¶ÅÊ±ÇÂØπÈì∂Ë°åÁöÑÈ£éÈô©ÊéßÂà∂Êúâ‰ΩïÂΩ±ÂìçÔºü
                                    </div>
                                    <div class="model-response">
                                        <strong>Qianfan-VL:</strong> Êñá‰ª∂ÊèêÂá∫‰∫ÜÂõõÈ°πÊ†∏ÂøÉË¶ÅÊ±Ç:1Ôºâ‰∏•Ê†ºÊàøÂú∞‰∫ßÂºÄÂèëË¥∑Ê¨æÁÆ°ÁêÜÔºåÈôêÂà∂ËµÑÈáëÊµÅÂêëÊú™ÂêàËßÑÈ°πÁõÆÔºõ2ÔºâËßÑËåÉÂúüÂú∞ÂÇ®Â§áË¥∑Ê¨æÔºåÈôêÂà∂Ë¥∑Ê¨æÊØî‰æãÂíåÊúüÈôêÔºõ3ÔºâÂä†Âº∫‰ΩèÊàøÊ∂àË¥πË¥∑Ê¨æÁÆ°ÁêÜÔºåÂÆûÊñΩÂ∑ÆÂºÇÂåñÈ¶ñ‰ªòÊØî‰æãÂíåÂà©ÁéáÔºõ4Ôºâ‰∏•ÊéßÂïÜ‰∏öÁî®ÊàøË¥∑Ê¨æ„ÄÇËøô‰∫õË¶ÅÊ±ÇÈÄöËøáÈôêÂà∂ËµÑÈáëËøáÂ∫¶ÊµÅÂÖ•ÊàøÂú∞‰∫ß„ÄÅÊèêÈ´òË¥∑Ê¨æÈó®ÊßõÂíåÂ∑ÆÂºÇÂåñÂÆö‰ª∑ÔºåÊúâÊïàÈôç‰Ωé‰∫ÜÈì∂Ë°å‰ø°Ë¥∑È£éÈô©ÔºåÈò≤Ê≠¢‰∫ÜÊàøÂú∞‰∫ßÊ≥°Ê≤´„ÄÇ
                                    </div>
                                </div>
                            </div>
                                        </div>

                                        <!-- Table Understanding -->
                                        <div class="capability-card">
                                            <h4>Table Understanding</h4>
                            <div class="showcase-content">
                                <div class="showcase-image">
                                    <img src="images/table_understanding.png" alt="Complex table">
                                </div>
                                <div class="showcase-dialogue">
                                    <div class="user-prompt">
                                        <strong>User:</strong> Â∞ÜË°®Ê†ºËß£Êûê‰∏∫HTMLÊ†ºÂºèÔºå‰øùÁïôÂêàÂπ∂ÂçïÂÖÉÊ†ºÁªìÊûÑ
                                    </div>
                                    <div class="model-response">
                                        
                                        <table border="1">
                                            <thead>
                                                <tr>
                                                    <th>È°πÁõÆ</th> <th>ÊúüÊú´‰ΩôÈ¢ù</th> <th>Âπ¥Âàù‰ΩôÈ¢ù</th>
                                                </tr>
                                            </thead>
                                            <tbody>
                                                <tr>  <td colspan="3">ÊµÅÂä®ËµÑ‰∫ßÔºö</td>  </tr>
                                                <tr>  <td>Ë¥ßÂ∏ÅËµÑÈáë</td> <td>5,288,011,738.39</td> <td>2,629,981,089.49</td>  </tr>
                                                <tr>  <td>ÁªìÁÆóÂ§á‰ªòÈáë</td> <td></td> <td></td>  </tr>
                                                <tr>  <td>ÊãÜÂá∫ËµÑÈáë</td> <td></td> <td></td>  </tr>
                                                <tr>  <td>‰ª•ÂÖ¨ÂÖÅ‰ª∑ÂÄºËÆ°Èáè‰∏îÂÖ∂ÂèòÂä®ËÆ°ÂÖ•ÂΩìÊúüÊçüÁõäÁöÑÈáëËûçËµÑ‰∫ß</td> <td>3,226,301.37</td> <td>6,830,273.97</td>  </tr>
                                                <tr>  <td>Ë°çÁîüÈáëËûçËµÑ‰∫ß</td> <td></td> <td></td>  </tr>
                                                <tr>  <td>Â∫îÊî∂Á•®ÊçÆ</td> <td>1,010,636.94</td> <td>888,800.00</td>  </tr>
                                                <tr>  <td>Â∫îÊî∂Ë¥¶Ê¨æ</td> <td>389,409,537.65</td> <td>290,733,812.62</td>  </tr>
                                                <tr>  <td>È¢Ñ‰ªòÊ¨æÈ°π</td> <td>474,301,533.93</td> <td>509,510,514.92</td>  </tr>
                                                <tr>  <td>Â∫îÊî∂‰øùË¥π</td> <td></td> <td></td>  </tr>
                                                <tr>  <td>Â∫îÊî∂ÂàÜ‰øùË¥¶Ê¨æ</td> <td></td> <td></td>  </tr>
                                                <tr>  <td>Â∫îÊî∂ÂàÜ‰øùÂêàÂêåÂáÜÂ§áÈáë</td> <td></td> <td></td>  </tr>
                                                <tr>  <td>Â∫îÊî∂Âà©ÊÅØ</td> <td>8,746,899.35</td> <td>1,645,890.39</td>  </tr>
                                                <tr>  <td>Â∫îÊî∂ËÇ°Âà©</td> <td></td> <td></td>  </tr>
                                                <tr>  <td>ÂÖ∂‰ªñÂ∫îÊî∂Ê¨æ</td> <td>291,499,926.83</td> <td>364,426,205.02</td>  </tr>
                                                <tr>  <td>‰π∞ÂÖ•ËøîÂîÆÈáëËûçËµÑ‰∫ß</td> <td></td> <td></td>  </tr>
                                                <tr>  <td>Â≠òË¥ß</td> <td>69,558,687.59</td> <td>79,651,862.50</td>  </tr>
                                                <tr>  <td>ÂàíÂàÜ‰∏∫ÊåÅÊúâÂæÖÂîÆÁöÑËµÑ‰∫ß</td> <td></td> <td></td>  </tr>
                                                <tr>  <td>‰∏ÄÂπ¥ÂÜÖÂà∞ÊúüÁöÑÈùûÊµÅÂä®ËµÑ‰∫ß</td> <td></td> <td></td>  </tr>
                                                <tr>  <td>ÂÖ∂‰ªñÊµÅÂä®ËµÑ‰∫ß</td> <td>533,938,653.95</td> <td>545,184,036.20</td>  </tr>
                                                <tr>  <td>ÊµÅÂä®ËµÑ‰∫ßÂêàËÆ°</td> <td>7,059,703,916.00</td> <td>4,428,852,485.11</td>  </tr>
                                                <tr>  <td colspan="3">ÈùûÊµÅÂä®ËµÑ‰∫ßÔºö</td>  </tr>
                                                <tr>  <td>ÂèëÊîæË¥∑Ê¨æÂíåÂû´Ê¨æ</td> <td></td> <td></td>  </tr>
                                                <tr>  <td>ÂèØ‰æõÂá∫ÂîÆÈáëËûçËµÑ‰∫ß</td> <td>981,477,845.00</td> <td>42,732,350.00</td>  </tr>
                                                <tr>  <td>ÊåÅÊúâËá≥Âà∞ÊúüÊäïËµÑ</td> <td></td> <td></td>  </tr>
                                                <tr>  <td>ÈïøÊúüÂ∫îÊî∂Ê¨æ</td> <td></td> <td></td>  </tr>
                                                <tr>  <td>ÈïøÊúüËÇ°ÊùÉÊäïËµÑ</td> <td>478,328,423.92</td> <td>482,914,333.17</td>  </tr>
                                                <tr>  <td>ÊäïËµÑÊÄßÊàøÂú∞‰∫ß</td> <td></td> <td></td>  </tr>
                                                <tr>  <td>Âõ∫ÂÆöËµÑ‰∫ß</td> <td>11,211,345,599.37</td> <td>11,517,509,788.66</td>  </tr>
                                                <tr>  <td>Âú®Âª∫Â∑•Á®ã</td> <td>344,034,065.45</td> <td>558,797,792.68</td>  </tr>
                                            </tbody>
                                        </table>
                                    </div>
                                </div>
                            </div>
                        </div>

                                        <!-- Chart Reasoning -->
                                        <div class="capability-card">
                                            <h4>Chart Reasoning</h4>
                            <div class="showcase-content">
                                <div class="showcase-image">
                                    <img src="images/chart_gift_reasoning.jpeg" alt="Gift selection chart">
                                </div>
                                <div class="showcase-dialogue">
                                    <div class="user-prompt">
                                        <strong>User:</strong> Â∞èÊòéÊòØ‰∏Ä‰ΩçÁî∑ÁîüÔºå‰∏ãÈù¢Âì™Ê†∑Áâ©ÂìÅÊúÄÈÄÇÂêà‰Ωú‰∏∫‰ªñÁöÑ‰∏ÉÂ§ïËäÇÁ§ºÁâ© a) Iphone 17 b) DiorÈ¶ôÊ∞¥ c) ‰∏ÄÊùüÁæé‰∏ΩÁöÑÈ≤úËä± d) Â∑ßÂÖãÂäõÂ•óË£Ö
                                    </div>
                                    <div class="model-response">
                                        <strong>Qianfan-VL:</strong> Ê†πÊçÆÂõæË°®Êï∞ÊçÆÔºåÁî∑ÁîüÊúÄÊÉ≥Êî∂Âà∞ÁöÑÁ§ºÁâ©‰∏≠ÔºåÊâãÊú∫ÁöÑÁÉ≠Â∫¶ÊåáÊï∞‰∏∫44.36ÔºåÈ´ò‰∫éÈ¶ôÊ∞¥Ôºà47.62Ôºâ„ÄÅÂ∑ßÂÖãÂäõÂ•óË£ÖÔºà42.48ÔºâÂíåÈ≤úËä±Ôºà41.22Ôºâ„ÄÇ

ÈÄâÈ°πÂàÜÊûêÔºö
- a) iphone17ÔºöÂ±û‰∫éÊâãÊú∫Á±ªÔºåÁ¨¶ÂêàÁî∑ÁîüÂØπÁîµÂ≠ê‰∫ßÂìÅÁöÑÂÅèÂ•ΩÔºåÁÉ≠Â∫¶ÊåáÊï∞Âú®Áî∑ÁîüÁ§ºÁâ©‰∏≠Â§Ñ‰∫éËæÉÈ´òÊ∞¥Âπ≥Ôºà‰ªÖÊ¨°‰∫éÊ∏∏ÊàèËÆæÂ§áÔºâ„ÄÇ
- b) DiorÈ¶ôÊ∞¥ÔºöÂ•≥ÁîüÂØπÈ¶ôÊ∞¥ÁöÑÁÉ≠Â∫¶Ôºà87.13ÔºâËøúÈ´ò‰∫éÁî∑ÁîüÔºà47.62ÔºâÔºå‰∏îÁî∑ÁîüÂØπÈ¶ôÊ∞¥ÁöÑÂÖ¥Ë∂£ËæÉ‰Ωé„ÄÇ
- c) ‰∏ÄÊùüÁæé‰∏ΩÁöÑÈ≤úËä±ÔºöÁî∑ÁîüÂØπËä±ÁöÑÂÖ¥Ë∂£ÊòéÊòæ‰Ωé‰∫éÂ•≥ÁîüÔºàÁî∑ÁîüËä±ÁöÑÁÉ≠Â∫¶41.22ÔºâÔºåÈÄöÂ∏∏‰∏çË¢´ËßÜ‰∏∫Áî∑ÁîüÂÅèÂ•ΩÁöÑÁ§ºÁâ©„ÄÇ
- d) Â∑ßÂÖãÂäõÂ•óË£ÖÔºöÂ•≥ÁîüÂØπÂ∑ßÂÖãÂäõÁöÑÁÉ≠Â∫¶Ôºà42.48ÔºâÈ´ò‰∫éÁî∑ÁîüÔºà47.62ÔºâÔºå‰∏îÂ∑ßÂÖãÂäõ‰Ωú‰∏∫Á§ºÁâ©Êõ¥ÂÅèÂêë"Â§ß‰ºóÂåñ"ÔºåËÄåÈùûÁî∑ÁîüÊ†∏ÂøÉÂÖ¥Ë∂£„ÄÇ

ÊúÄÈÄÇÂêàÁöÑÁ§ºÁâ©ÊòØa) iphone17„ÄÇ
Á≠îÊ°àÔºöa
                                    </div>
                                </div>
                            </div>
                                        </div>

                                        <!-- Chart Calculation -->
                                        <div class="capability-card">
                                            <h4>Chart Calculation</h4>
                            <div class="showcase-content">
                                <div class="showcase-image">
                                    <img src="images/chart_math_calculation.png" alt="AI sentiment chart">
                                </div>
                                <div class="showcase-dialogue">
                                    <div class="user-prompt">
                                        <strong>User:</strong> What is the average percentage of U.S. adults who feel equally excited and concerned about AI over the three years?
                                    </div>
                                    <div class="model-response">
                                        <strong>Qianfan-VL:</strong> To determine the average percentage of U.S. adults who feel "equally excited and concerned" about AI over the three years (2021, 2022, 2023), follow these steps:

Step 1: Identify the relevant data
From the chart, the percentage of adults who feel "equally excited and concerned" is:
- 2021: 45%
- 2022: 46%
- 2023: 36%

Step 2: Calculate the average
Add the percentages and divide by the number of years (3):

Average = (45 + 46 + 36) / 3 = 127 / 3 ‚âà 42.33%

Answer: Approximately 42.3% (or 42.33%).
                                    </div>
                                </div>
                            </div>
                                        </div>

                                        <!-- Stock Chart Analysis -->
                                        <div class="capability-card">
                                            <h4>Stock Chart Analysis</h4>
                            <div class="showcase-content">
                                <div class="showcase-image">
                                    <img src="images/chart_stock_elaboration.png" alt="Shanghai stock index chart">
                                </div>
                                <div class="showcase-dialogue">
                                    <div class="user-prompt">
                                        <strong>User:</strong> ÊèèËø∞‰∏Ä‰∏ã8Êúà27Âè∑ÁöÑ‰∏äËØÅÊåáÊï∞Ëµ∞Âäø
                                    </div>
                                    <div class="model-response">
                                        <strong>Qianfan-VL:</strong> 8Êúà27Êó•Ôºå‰∏äËØÅÊåáÊï∞ÂÖ®Â§©ÂëàÁé∞ÈúáËç°‰∏ãË∑åËµ∞Âäø„ÄÇÂºÄÁõòÂêéÊåáÊï∞Âú®3869.61ÁÇπËµ∑Ê≠•ÔºåÊúÄÈ´òËß¶Âèä3887.20ÁÇπÔºåÈöèÂêéÈÄêÊ≠•ÂõûËêΩ„ÄÇÊó©ÁõòÁª¥ÊåÅÈúáËç°Êï¥ÁêÜÊÄÅÂäøÔºåÂçàÂ∏ÇÂêéË∑åÂπÖÈÄêÊ∏êÊâ©Â§ßÔºåÊúÄÁªàÊî∂‰∫é3800.35ÁÇπÔºå‰∏ãË∑å68.03ÁÇπÔºåË∑åÂπÖ1.76%„ÄÇÂÖ®Â§©Êàê‰∫§ÈáèËææ8.59‰∫øÊâãÔºåÊàê‰∫§È¢ù‰∏∫1.33‰∏á‰∫øÂÖÉÔºåÂ∏ÇÂú∫‰∫§ÊäïÊ¥ªË∑É„ÄÇ‰ªéÂàÜÊó∂ÂõæÁúãÔºåÊåáÊï∞Âú®ÂçàÂêé14:30Â∑¶Âè≥Âá∫Áé∞ÊòéÊòæË∑≥Ê∞¥ÔºåË∑åÂπÖËøõ‰∏ÄÊ≠•Êâ©Â§ßÔºåÊúÄÁªà‰ª•ÂÖ®Êó•‰ΩéÁÇπÊî∂Áõò„ÄÇ
                                    </div>
                                </div>
                            </div>
                                        </div>
                                    </div>
                                </div>
                                <button class="carousel-btn carousel-next" aria-label="Next">‚Ä∫</button>
                            </div>
                        </div>

                        <!-- Video Understanding Panel -->
                        <div class="capability-panel" id="video-panel">
                            <div class="carousel-container">
                                <button class="carousel-btn carousel-prev" aria-label="Previous">‚Äπ</button>
                                <div class="carousel-wrapper">
                                    <div class="carousel-track">
                                        <!-- Video Content Analysis -->
                                        <div class="capability-card">
                                            <h4>Video Content Analysis</h4>
                                            <div class="showcase-content">
                                                <div class="showcase-image">
                                                    <video controls style="width: 100%;">
                                                        <source src="images/video_understanding.mp4" type="video/mp4">
                                                        Your browser does not support the video tag.
                                                    </video>
                                                </div>
                                                <div class="showcase-dialogue">
                                                    <div class="user-prompt">
                                                        <strong>User:</strong> ËØ∑ÊèèËø∞‰∏Ä‰∏ãËßÜÈ¢ë‰∏≠ÁöÑÂÜÖÂÆπ
                                                    </div>
                                                    <div class="model-response">
                                                        <strong>Qianfan-VL:</strong> Âú®ËøôÊÆµÂÆÅÈùôÁ••ÂíåÁöÑËßÜÈ¢ë‰∏≠Ôºå‰∏ÄÁâáÂÆΩÈòîÁöÑÊπñÊ≥äÊò†ÂÖ•ÁúºÂ∏òÔºåÊπñÈù¢Ê≥¢ÂÖâÁ≤ºÁ≤ºÔºåÂèçÂ∞ÑÁùÄÊ∏©ÊöñÁöÑÈò≥ÂÖâ„ÄÇÂá†ËâòÂ∞èËàπÊï£Â∏ÉÂú®ÊπñÈù¢‰∏äÔºåÊúâÁöÑÈù†ËøëÂ≤∏ËæπÔºåÊúâÁöÑÂú®ÊπñÂøÉÊÇ†ÁÑ∂Ë°åÈ©∂„ÄÇËøúÂ§ÑÔºåËåÇÂØÜÁöÑÊ†ëÊûóÂíåËøûÁªµËµ∑‰ºèÁöÑÂ±±ËÑâÊûÑÊàê‰∫Ü‰∏ÄÂπÖÁæé‰∏ΩÁöÑÁîªÂç∑‚Ä¶
                                                    </div>
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                </div>
                                <button class="carousel-btn carousel-next" aria-label="Next">‚Ä∫</button>
                            </div>
                        </div>

                        <!-- Grounding and Counting Panel -->
                        <div class="capability-panel" id="grounding-panel">
                            <div class="carousel-container">
                                <button class="carousel-btn carousel-prev" aria-label="Previous">‚Äπ</button>
                                <div class="carousel-wrapper">
                                    <div class="carousel-track">
                                        <!-- Object Grounding -->
                                        <div class="capability-card">
                                            <h4>Object Grounding</h4>
                                            <div class="showcase-content">
                                                <div class="showcase-image">
                                                    <img src="images/object_grounding_result.jpg" alt="Animals with cat localization">
                                                </div>
                                                <div class="showcase-dialogue">
                                                    <div class="user-prompt">
                                                        <strong>User:</strong> Please provide the bounding box coordinate of the region this sentence describes: &lt;ref&gt;cat in the middle&lt;/ref&gt;
                                                    </div>
                                                    <div class="model-response">
                                                        <strong>Qianfan-VL:</strong> &lt;ref&gt;cat in the middle&lt;/ref&gt;&lt;box&gt;[[416, 577, 694, 804]]&lt;/box&gt;
                                                    </div>
                                                </div>
                                            </div>
                                        </div>

                                        <!-- Object Counting -->
                                        <div class="capability-card">
                                            <h4>Object Counting</h4>
                                            <div class="showcase-content">
                                                <div class="showcase-image">
                                                    <img src="images/object_counting.jpg" alt="Multiple watermelons">
                                                </div>
                                                <div class="showcase-dialogue">
                                                    <div class="user-prompt">
                                                        <strong>User:</strong> Âõæ‰∏≠ÊúâÂá†‰∏™Ë•øÁìú
                                                    </div>
                                                    <div class="model-response">
                                                        <strong>Qianfan-VL:</strong> 10
                                                    </div>
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                </div>
                                <button class="carousel-btn carousel-next" aria-label="Next">‚Ä∫</button>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <section id="api" class="section">
                <h2>Getting Started</h2>
                
                <h3>Installation</h3>
                <pre><code class="language-bash"># Install OpenAI SDK
pip install openai

# Set up authentication (using Qianfan credentials)
export QIANFAN_ACCESS_KEY="your_access_key"
export QIANFAN_SECRET_KEY="your_secret_key"</code></pre>

                <h3>Basic Setup</h3>
                <pre><code class="language-python">from openai import OpenAI
import base64
import os

# Initialize client with Qianfan endpoint
client = OpenAI(
    api_key = os.environ.get("QIANFAN_SECRET_KEY"),
    base_url = "https://api.qianfan.com/v1",
    default_headers = {
        "X-Access-Key": os.environ.get("QIANFAN_ACCESS_KEY")
    }
)

# Available models: Qianfan-VL-8B, Qianfan-VL-70B
# Note: Qianfan-VL-3B will be available soon
model = "Qianfan-VL-8B"</code></pre>

                <h3>Code Examples by Capability</h3>
                
                <div class="code-examples-container">
                    <!-- Code Example Tabs -->
                    <div class="code-tabs">
                        <button class="code-tab active" data-tab="ocr-code">OCR</button>
                        <button class="code-tab" data-tab="math-code">Math Solving</button>
                        <button class="code-tab" data-tab="document-code">Document Understanding</button>
                        <button class="code-tab" data-tab="video-code">Video Analysis</button>
                        <button class="code-tab" data-tab="grounding-code">Grounding & Counting</button>
                    </div>

                    <!-- Code Panels -->
                    <div class="code-panels">
                        <!-- OCR Code Panel -->
                        <div class="code-panel active" id="ocr-code-panel">
                            <h4>OCR and Text Extraction</h4>
                            <pre><code class="language-python">from openai import OpenAI
import base64
import os

client = OpenAI(
    api_key = os.environ.get("QIANFAN_SECRET_KEY"),
    base_url = "https://api.qianfan.com/v1",
    default_headers = {"X-Access-Key": os.environ.get("QIANFAN_ACCESS_KEY")}
)

# Read and encode image
with open("handwritten_text.jpg", "rb") as image_file:
    image_base64 = base64.b64encode(image_file.read()).decode('utf-8')

# OCR for handwritten text
response = client.chat.completions.create(
    model = "Qianfan-VL-8B",
    messages=[
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "ËØ∑ËØÜÂà´Âõæ‰∏≠ÁöÑÊâãÂÜôÊñáÂ≠óÔºåÂπ∂ËΩ¨Êç¢‰∏∫ÁÆÄ‰Ωì‰∏≠Êñá"},
                {
                    "type": "image_url",
                    "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}
                }
            ]
        }
    ],
    temperature = 0.1,  # Lower temperature for accurate OCR
    max_tokens = 2048
)

print(response.choices[0].message.content)

# Scene text extraction
scene_response = client.chat.completions.create(
    model = "Qianfan-VL-8B",
    messages=[
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "ÊèêÂèñÂõæÁâá‰∏≠ÊâÄÊúâÁöÑÊñáÂ≠ó‰ø°ÊÅØÔºåÂåÖÊã¨ÊãõÁâå„ÄÅÊ†áËØ≠Á≠â"},
                {
                    "type": "image_url",
                    "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}
                }
            ]
        }
    ]
)

# Extract structured information from forms
form_response = client.chat.completions.create(
    model = "Qianfan-VL-8B",
    messages=[
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "ÊèêÂèñË°®Âçï‰∏≠ÁöÑÂÖ≥ÈîÆ‰ø°ÊÅØÔºåËæìÂá∫‰∏∫JSONÊ†ºÂºè"},
                {
                    "type": "image_url",
                    "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}
                }
            ]
        }
    ]
)</code></pre>
                        </div>

                        <!-- Math Code Panel -->
                        <div class="code-panel" id="math-code-panel">
                            <h4>Mathematical Problem Solving</h4>
                            <pre><code class="language-python">from openai import OpenAI
import base64
import os

client = OpenAI(
    api_key = os.environ.get("QIANFAN_SECRET_KEY"),
    base_url = "https://api.qianfan.com/v1",
    default_headers = {"X-Access-Key": os.environ.get("QIANFAN_ACCESS_KEY")}
)

# Read math problem image
with open("math_problem.jpg", "rb") as image_file:
    image_base64 = base64.b64encode(image_file.read()).decode('utf-8')

# Solve with step-by-step explanation
response = client.chat.completions.create(
    model = "Qianfan-VL-70B",  # Use larger model for complex math
    messages=[
        {
            "role": "user",
            "content": [
                {
                    "type": "text", 
                    "text": """ËØ∑Ëß£ÂÜ≥ËøôÈÅìÊï∞Â≠¶È¢òÔºåË¶ÅÊ±ÇÔºö
1. ËØ¶ÁªÜËØ¥ÊòéËß£È¢òÊÄùË∑Ø
2. ÁªôÂá∫ÊØè‰∏ÄÊ≠•ÁöÑÊé®ÂØºËøáÁ®ã
3. ‰ΩøÁî®LaTeXÊ†ºÂºè‰π¶ÂÜôÊï∞Â≠¶ÂÖ¨Âºè
4. ÊúÄÂêéÁªôÂá∫Á≠îÊ°à"""
                },
                {
                    "type": "image_url",
                    "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}
                }
            ]
        }
    ],
    temperature = 0.2,
    max_tokens = 4096
)

print(response.choices[0].message.content)

# Geometry problem solving
geometry_response = client.chat.completions.create(
    model = "Qianfan-VL-70B",
    messages=[
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": "ÂàÜÊûêËøôÈÅìÂá†‰ΩïÈ¢òÔºåÁîªÂá∫ËæÖÂä©Á∫øÂπ∂ËØ¥ÊòéËß£È¢òÊ≠•È™§"
                },
                {
                    "type": "image_url",
                    "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}
                }
            ]
        }
    ]
)

# Extract mathematical equations
equation_response = client.chat.completions.create(
    model = "Qianfan-VL-8B",
    messages=[
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "Â∞ÜÂõæ‰∏≠ÁöÑÊï∞Â≠¶ÂÖ¨ÂºèËΩ¨Êç¢‰∏∫LaTeXÊ†ºÂºè"},
                {
                    "type": "image_url",
                    "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}
                }
            ]
        }
    ]
)</code></pre>
                        </div>

                        <!-- Document Code Panel -->
                        <div class="code-panel" id="document-code-panel">
                            <h4>Document Understanding</h4>
                            <pre><code class="language-python">from openai import OpenAI
import base64
import os

client = OpenAI(
    api_key = os.environ.get("QIANFAN_SECRET_KEY"),
    base_url = "https://api.qianfan.com/v1",
    default_headers = {"X-Access-Key": os.environ.get("QIANFAN_ACCESS_KEY")}
)

# Read document image
with open("document.jpg", "rb") as image_file:
    image_base64 = base64.b64encode(image_file.read()).decode('utf-8')

# Extract and analyze document content
response = client.chat.completions.create(
    model = "Qianfan-VL-8B",
    messages=[
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": """ËØ∑ÂàÜÊûêËøô‰ªΩÊñáÊ°£Ôºö
1. ÊèêÂèñÊñáÊ°£ÁöÑ‰∏ªË¶ÅÂÜÖÂÆπÂíåÂÖ≥ÈîÆ‰ø°ÊÅØ
2. ËØÜÂà´ÊñáÊ°£Á±ªÂûãÔºàÂêàÂêå„ÄÅÊä•Âëä„ÄÅË¥¢Âä°Êä•Ë°®Á≠âÔºâ
3. ÊÄªÁªìÊ†∏ÂøÉË¶ÅÁÇπ
4. Ê†áÊ≥®ÈáçË¶ÅÊù°Ê¨æÊàñÊï∞ÊçÆ"""
                },
                {
                    "type": "image_url",
                    "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}
                }
            ]
        }
    ],
    temperature = 0.1,
    max_tokens = 3000
)

print(response.choices[0].message.content)

# Table extraction and analysis
table_response = client.chat.completions.create(
    model = "Qianfan-VL-8B",
    messages=[
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": """ËØ∑ÊèêÂèñË°®Ê†ºÂÜÖÂÆπÔºö
1. Â∞ÜË°®Ê†ºËΩ¨Êç¢‰∏∫MarkdownÊ†ºÂºè
2. ‰øùÁïôÊâÄÊúâÂêàÂπ∂ÂçïÂÖÉÊ†ºÁöÑÁªìÊûÑ
3. ËÆ°ÁÆóÂÖ≥ÈîÆÊåáÊ†áÔºàÂ¶ÇÊúâÔºâ
4. ÂàÜÊûêÊï∞ÊçÆË∂ãÂäø"""
                },
                {
                    "type": "image_url",
                    "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}
                }
            ]
        }
    ]
)

# Chart analysis
chart_response = client.chat.completions.create(
    model = "Qianfan-VL-70B",
    messages=[
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": "ÂàÜÊûêËøô‰∏™ÂõæË°®ÔºåÊèêÂèñÊï∞ÊçÆÂπ∂ÁªôÂá∫Ê¥ûÂØü"
                },
                {
                    "type": "image_url",
                    "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}
                }
            ]
        }
    ]
)</code></pre>
                        </div>

                        <!-- Video Code Panel -->
                        <div class="code-panel" id="video-code-panel">
                            <h4>Video Understanding</h4>
                            <pre><code class="language-python">from openai import OpenAI
import base64
import os
import cv2

client = OpenAI(
    api_key = os.environ.get("QIANFAN_SECRET_KEY"),
    base_url = "https://api.qianfan.com/v1",
    default_headers = {"X-Access-Key": os.environ.get("QIANFAN_ACCESS_KEY")}
)

# Extract key frames from video
def extract_frames(video_path, num_frames = 8):
    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    frame_indices = [i * total_frames // num_frames for i in range(num_frames)]
    
    frames = []
    for idx in frame_indices:
        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
        ret, frame = cap.read()
        if ret:
            _, buffer = cv2.imencode('.jpg', frame)
            frame_base64 = base64.b64encode(buffer).decode('utf-8')
            frames.append(frame_base64)
    
    cap.release()
    return frames

# Extract frames
frames = extract_frames("video.mp4", num_frames = 8)

# Analyze video content
content = []
for i, frame in enumerate(frames):
    content.append({"type": "text", "text": f"Frame {i+1}:"})
    content.append({
        "type": "image_url",
        "image_url": {"url": f"data:image/jpeg;base64,{frame}"}
    })

content.append({"type": "text", "text": """ËØ∑ÂàÜÊûêËøô‰∏™ËßÜÈ¢ëÔºö
1. ÊèèËø∞ËßÜÈ¢ëÁöÑÊï¥‰ΩìÂÜÖÂÆπ
2. ËØÜÂà´‰∏ªË¶ÅÂú∫ÊôØÂíåÊ¥ªÂä®
3. ÊèêÂèñÂÖ≥ÈîÆÊó∂Âàª
4. ÊÄªÁªìËßÜÈ¢ëÁöÑ‰∏ªÈ¢ò"""})

response = client.chat.completions.create(
    model = "Qianfan-VL-70B",
    messages=[{"role": "user", "content": content}],
    temperature = 0.3,
    max_tokens = 2048
)

print(response.choices[0].message.content)

# Action recognition
action_response = client.chat.completions.create(
    model = "Qianfan-VL-8B",
    messages=[
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "ËØÜÂà´ËßÜÈ¢ë‰∏≠ÁöÑÂä®‰ΩúÂíåË°å‰∏∫"},
                *[{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{f}"}} for f in frames[:4]]
            ]
        }
    ]
)</code></pre>
                        </div>

                        <!-- Grounding Code Panel -->
                        <div class="code-panel" id="grounding-code-panel">
                            <h4>Grounding and Counting</h4>
                            <pre><code class="language-python">from openai import OpenAI
import base64
import os
import json

client = OpenAI(
    api_key = os.environ.get("QIANFAN_SECRET_KEY"),
    base_url = "https://api.qianfan.com/v1",
    default_headers = {"X-Access-Key": os.environ.get("QIANFAN_ACCESS_KEY")}
)

# Read image
with open("objects.jpg", "rb") as image_file:
    image_base64 = base64.b64encode(image_file.read()).decode('utf-8')

# Object grounding with bounding boxes
grounding_response = client.chat.completions.create(
    model = "Qianfan-VL-8B",
    messages=[
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": "Please provide the bounding box coordinates for: <ref>the red car in the middle</ref>"
                },
                {
                    "type": "image_url",
                    "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}
                }
            ]
        }
    ],
    temperature = 0.1,
    max_tokens = 512
)

# Parse bounding box from response
response_text = grounding_response.choices[0].message.content
print(f"Grounding result: {response_text}")

# Object counting
counting_response = client.chat.completions.create(
    model = "Qianfan-VL-8B",
    messages=[
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "ËØ∑Êï∞‰∏Ä‰∏ãÂõæ‰∏≠ÊúâÂ§öÂ∞ë‰∏™‰∫∫„ÄÅÂ§öÂ∞ëËæÜËΩ¶„ÄÅÂ§öÂ∞ëÊ£µÊ†ë"},
                {
                    "type": "image_url",
                    "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}
                }
            ]
        }
    ],
    temperature = 0.1,
    max_tokens = 256
)

print(f"Counting result: {counting_response.choices[0].message.content}")

# Detailed object detection
detection_response = client.chat.completions.create(
    model = "Qianfan-VL-70B",
    messages=[
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": """ËØ∑Ê£ÄÊµãÂõæ‰∏≠ÊâÄÊúâÂØπË±°ÔºåËæìÂá∫JSONÊ†ºÂºèÔºö
{
  "objects": [
    {"name": "ÂØπË±°ÂêçÁß∞", "count": Êï∞Èáè, "location": "‰ΩçÁΩÆÊèèËø∞"},
    ...
  ]
}"""
                },
                {
                    "type": "image_url",
                    "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}
                }
            ]
        }
    ],
    temperature = 0.1,
    max_tokens = 1024
)

# Parse JSON response
try:
    objects = json.loads(detection_response.choices[0].message.content)
    print(json.dumps(objects, ensure_ascii = False, indent = 2))
except json.JSONDecodeError:
    print(detection_response.choices[0].message.content)</code></pre>
                        </div>
                    </div>
                </div>

                <h3>API Parameters</h3>
                <table class="api-table">
                    <thead>
                        <tr>
                            <th>Parameter</th>
                            <th>Type</th>
                            <th>Default</th>
                            <th>Description</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><code>model</code></td>
                            <td>string</td>
                            <td>required</td>
                            <td>Available models: "Qianfan-VL-8B", "Qianfan-VL-70B" (3B coming soon)</td>
                        </tr>
                        <tr>
                            <td><code>messages</code></td>
                            <td>array</td>
                            <td>required</td>
                            <td>Array of message objects with role and content</td>
                        </tr>
                        <tr>
                            <td><code>temperature</code></td>
                            <td>float</td>
                            <td>0.7</td>
                            <td>Sampling temperature (0.0 to 2.0)</td>
                        </tr>
                        <tr>
                            <td><code>max_tokens</code></td>
                            <td>integer</td>
                            <td>2048</td>
                            <td>Maximum tokens to generate</td>
                        </tr>
                        <tr>
                            <td><code>top_p</code></td>
                            <td>float</td>
                            <td>1.0</td>
                            <td>Nucleus sampling parameter</td>
                        </tr>
                        <tr>
                            <td><code>stream</code></td>
                            <td>boolean</td>
                            <td>false</td>
                            <td>Enable streaming responses</td>
                        </tr>
                    </tbody>
                </table>
            </section>

            <section id="conclusion" class="section">
                <h2>Conclusion</h2>
                
                <p>
                    Qianfan-VL represents a significant step forward in making multimodal AI practical for enterprise applications. 
                    By combining general capabilities with domain-specific enhancements, efficient training on domestic hardware, 
                    and a comprehensive model family, Qianfan-VL offers a compelling solution for organizations looking to leverage multimodal AI.
                </p>
                
                <p>
                    The model's success in bridging the gap between research and production, particularly in challenging domains like OCR 
                    and document understanding, demonstrates the value of targeted enhancement while maintaining broad capabilities. 
                    As multimodal understanding becomes essential for enterprise intelligence, Qianfan-VL provides a robust foundation 
                    for the next generation of AI applications.
                </p>

                <div class="cta-section">
                    <h3>Get Started with Qianfan-VL</h3>
                    <p>Experience the power of domain-enhanced multimodal understanding</p>
                    <a href="https://console.bce.baidu.com/qianfan" class="btn btn-primary">Access Console</a>
                    <a href="https://cloud.baidu.com/doc/WENXINWORKSHOP" class="btn btn-secondary">Read Documentation</a>
                    <a href="https://github.com/baidubce/qianfan-models-cookbook" class="btn btn-secondary">View Examples</a>
                </div>
            </section>

            <section id="resources" class="section">
                <h2>Resources & Support</h2>
                
                <div class="resources-grid">
                    <div class="resource-card">
                        <h3>Documentation</h3>
                        <ul>
                            <li><a href="https://cloud.baidu.com/doc/WENXINWORKSHOP">API Documentation</a></li>
                            <li><a href="https://github.com/baidubce/qianfan-models-cookbook">Code Examples</a></li>
                            <li><a href="https://console.bce.baidu.com/qianfan">Console</a></li>
                        </ul>
                    </div>
                    
                    <div class="resource-card">
                        <h3>Community</h3>
                        <ul>
                            <li><a href="https://ai.baidu.com/forum">Discussion Forum</a></li>
                            <li><a href="https://github.com/baidubce">GitHub Organization</a></li>
                            <li>WeChat: ÁôæÂ∫¶Êô∫ËÉΩ‰∫ëÂçÉÂ∏Ü</li>
                        </ul>
                    </div>
                    
                    <div class="resource-card">
                        <h3>Contact</h3>
                        <ul>
                            <li>Technical: qianfan-support@baidu.com</li>
                            <li>Business: qianfan-biz@baidu.com</li>
                            <li>Research: qianfan-research@baidu.com</li>
                        </ul>
                    </div>
                </div>
            </section>
        </div>
    </main>

    <footer class="site-footer">
        <div class="container">
            <div class="footer-content">
                <div class="footer-info">
                    <p>&copy; 2025 Baidu, Inc. All rights reserved.</p>
                    <p>Qianfan-VL is a product of Baidu AI Cloud.</p>
                </div>
                <div class="footer-links">
                    <a href="https://cloud.baidu.com">Baidu Cloud</a>
                    <a href="https://ai.baidu.com">Baidu AI</a>
                    <a href="https://ir.baidu.com">Investor Relations</a>
                    <a href="https://www.baidu.com/duty">Legal</a>
                </div>
            </div>
        </div>
    </footer>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-bash.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-json.min.js"></script>
</body>
</html>
